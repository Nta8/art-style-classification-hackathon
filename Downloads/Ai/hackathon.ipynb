{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":108151,"databundleVersionId":13105570,"sourceType":"competition"}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install gdown\n!gdown --id 1AsslIqApC-3Lg8K1CU7BtIpUPcmVlUF9","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FP4bykFjACTo","outputId":"102621df-0245-495a-b83b-26941d004ce6","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_csv('/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/train.csv')\nprint(df.head())","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-ui3ekr_AFOJ","outputId":"f78c6b8e-73b3-4488-de28-dd60d7d8e4ec","trusted":true,"execution":{"iopub.status.busy":"2025-09-02T14:02:02.308869Z","iopub.execute_input":"2025-09-02T14:02:02.309160Z","iopub.status.idle":"2025-09-02T14:02:02.617715Z","shell.execute_reply.started":"2025-09-02T14:02:02.309114Z","shell.execute_reply":"2025-09-02T14:02:02.616947Z"}},"outputs":[{"name":"stdout","text":"                                   uuid         style\n0  d5f389b5-2cce-4450-8a3f-b66ba8404a2e   Ink scenery\n1  8e122d11-8216-4af1-b059-dbf8507b9eb6   Ink scenery\n2  cca68598-f417-4c4f-b259-ab2e13aa0b7a         pixel\n3  d147e63b-499f-476b-aabb-96df5edfdc76  oil painting\n4  007df8a8-4ef0-404a-8c69-a63016512da8   Ink scenery\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os, copy, random, warnings\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom torchvision.transforms import AutoAugment, AutoAugmentPolicy\nfrom PIL import Image, ImageFile\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\n# ============================\n# 1) CONFIG & SEED\n# ============================\nCFG = {\n    \"image_dir\": \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/image\",\n    \"batch_size\": 32,\n    \"epochs_stage1\": 5,\n    \"epochs_stage2\": 25,\n    \"patience\": 6,\n    \"lr\": 3e-4,\n    \"weight_decay\": 1e-4,\n    \"label_smoothing\": 0.1,\n    \"ema_decay\": 0.999,\n    \"seed\": 42,\n    \"unk_threshold\": 0.4  # à¸–à¹‰à¸² max prob < threshold => UNK\n}\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_amp = (device.type == \"cuda\")\n\ndef seed_everything(seed=42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); \n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(CFG[\"seed\"])\nImageFile.LOAD_TRUNCATED_IMAGES = True\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ============================\n# 2) Dataset\n# ============================\nclass ArtDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_path = row['path']\n        label = row['label']\n        # à¸šà¸²à¸‡à¹„à¸Ÿà¸¥à¹Œà¸­à¸²à¸ˆà¸¡à¸µà¸›à¸±à¸à¸«à¸² à¹ƒà¸«à¹‰ retry/open à¹à¸šà¸š robust\n        with Image.open(img_path) as im:\n            image = im.convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# ============================\n# 3) Prepare Data\n# ============================\ntrain_csv = \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/train.csv\"\ndf = pd.read_csv(train_csv)\ndf['path'] = df['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\n\nlabel_to_idx = {label: idx for idx, label in enumerate(sorted(df['style'].unique()))}\nidx_to_label = {v: k for k, v in label_to_idx.items()}\ndf['label'] = df['style'].map(label_to_idx).astype(int)\n\ntrain_df, val_df = train_test_split(\n    df, test_size=0.2, stratify=df['label'], random_state=CFG[\"seed\"]\n)\n\n# Augs\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),\n                         (0.229, 0.224, 0.225))\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),\n                         (0.229, 0.224, 0.225))\n])\n\n# DataLoader à¸—à¸µà¹ˆà¸›à¸¥à¸­à¸”à¸ à¸±à¸¢à¸à¸±à¸š Kaggle/CPU-only\nnum_workers = min(4, os.cpu_count() or 1)\nuse_persistent = (num_workers > 0) and (device.type == \"cuda\")\n\ntrain_loader = DataLoader(\n    ArtDataset(train_df, train_transform),\n    batch_size=CFG[\"batch_size\"], shuffle=True, num_workers=num_workers,\n    pin_memory=(device.type==\"cuda\"), persistent_workers=use_persistent\n)\nval_loader = DataLoader(\n    ArtDataset(val_df, val_transform),\n    batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=num_workers,\n    pin_memory=(device.type==\"cuda\"), persistent_workers=use_persistent\n)\n\n# ============================\n# 4) Model\n# ============================\nnum_classes_orig = len(label_to_idx)\nnum_classes = num_classes_orig + 1  # à¹€à¸žà¸´à¹ˆà¸¡ UNK à¹€à¸›à¹‡à¸™à¸„à¸¥à¸²à¸ªà¸—à¹‰à¸²à¸¢\nmodel = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\nin_features = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(in_features, num_classes)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=CFG[\"label_smoothing\"])\nscaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n\noptimizer = optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer, T_max=CFG[\"epochs_stage1\"]+CFG[\"epochs_stage2\"]\n)\n\n# EMA model\nema_model = copy.deepcopy(model)\nfor p in ema_model.parameters():\n    p.requires_grad = False\n\n@torch.no_grad()\ndef update_ema(model, ema_model, decay):\n    msd, emsd = model.state_dict(), ema_model.state_dict()\n    for k in msd.keys():\n        emsd[k] = emsd[k] * decay + msd[k] * (1 - decay)\n\n# ============================\n# 5) Training Functions\n# ============================\ndef run_epoch(loader, train_mode=True):\n    model.train(train_mode)\n    running_loss, correct, total = 0.0, 0, 0\n\n    for images, labels in tqdm(loader, leave=False, desc=\"Train\" if train_mode else \"Val\"):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        optimizer.zero_grad(set_to_none=True)\n\n        with torch.cuda.amp.autocast(enabled=use_amp):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n\n        if train_mode:\n            scaler.scale(loss).backward()\n            scaler.step(optimizer)\n            scaler.update()\n            update_ema(model, ema_model, CFG[\"ema_decay\"])\n\n        running_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n\n    avg_loss = running_loss / max(1, len(loader))\n    acc = 100.0 * correct / max(1, total)\n    return avg_loss, acc\n\ndef set_backbone_freeze(freeze: bool):\n    if freeze:\n        for param in model.features.parameters():\n            param.requires_grad = False\n    else:\n        for param in model.parameters():\n            param.requires_grad = True\n\ndef validate_on_val():\n    # à¹ƒà¸Šà¹‰ model à¸›à¸±à¸ˆà¸ˆà¸¸à¸šà¸±à¸™ (à¹„à¸¡à¹ˆà¹ƒà¸Šà¹ˆ EMA) à¹€à¸žà¸·à¹ˆà¸­à¹ƒà¸«à¹‰à¹€à¸—à¸µà¸¢à¸šà¸œà¸¥à¸•à¹ˆà¸­à¹€à¸™à¸·à¹ˆà¸­à¸‡à¸à¸±à¸š training\n    model.eval()\n    loss, acc = run_epoch(val_loader, train_mode=False)\n    return loss, acc\n\ndef train_model(stage_epochs, freeze_backbone=True):\n    global best_acc, patience_counter, best_model_wts\n\n    set_backbone_freeze(freeze_backbone)\n\n    for epoch in range(stage_epochs):\n        print(f\"\\nEpoch {epoch+1}/{stage_epochs} | {'Freeze' if freeze_backbone else 'Unfreeze'} Backbone\")\n        train_loss, train_acc = run_epoch(train_loader, True)\n        val_loss, val_acc = validate_on_val()\n\n        scheduler.step()\n        print(f\"Train Loss {train_loss:.4f} | Acc {train_acc:.2f}% || Val Loss {val_loss:.4f} | Acc {val_acc:.2f}%\")\n\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n            torch.save(best_model_wts, \"best_model.pth\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG[\"patience\"]:\n                print(\"Early stopping.\")\n                return\n\n# ============================\n# 6) Training\n# ============================\nbest_acc, patience_counter = 0.0, 0\nbest_model_wts = copy.deepcopy(model.state_dict())\n\ntrain_model(CFG[\"epochs_stage1\"], freeze_backbone=True)\ntrain_model(CFG[\"epochs_stage2\"], freeze_backbone=False)\n\n# à¹‚à¸«à¸¥à¸”à¸™à¹‰à¸³à¸«à¸™à¸±à¸à¸—à¸µà¹ˆà¸”à¸µà¸—à¸µà¹ˆà¸ªà¸¸à¸”à¸à¸¥à¸±à¸šà¹€à¸‚à¹‰à¸² model à¹à¸¥à¸°à¸‹à¸´à¸‡à¸à¹Œà¹ƒà¸«à¹‰ ema_model à¸”à¹‰à¸§à¸¢\nmodel.load_state_dict(best_model_wts)\nema_model.load_state_dict(best_model_wts)\ntorch.save(model.state_dict(), \"last_model.pth\")\nprint(f\"âœ… Best Val Acc: {best_acc:.2f}% | saved best_model.pth & last_model.pth\")\n\n# ============================\n# 7) Inference + TTA + UNK\n# ============================\n# à¹€à¸žà¸´à¹ˆà¸¡ variety à¸‚à¸­à¸‡ TTA à¸­à¸µà¸à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢\ntta_transforms = [\n    # base\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ]),\n    # hflip\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomHorizontalFlip(p=1.0),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ]),\n    # rotation\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomRotation(15),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ]),\n    # center crop style\n    transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ]),\n    # jitter/perspective à¹€à¸¥à¹‡à¸à¸™à¹‰à¸­à¸¢\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ColorJitter(0.05, 0.05, 0.05, 0.02),\n        transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ]),\n]\n\n# à¹ƒà¸Šà¹‰ label_to_idx à¸ˆà¸²à¸ training + à¹€à¸žà¸´à¹ˆà¸¡ UNK\nidx_to_label = {v: k for k, v in label_to_idx.items()}\nidx_to_label[num_classes-1] = \"UNK\"\n\nsubmission = pd.read_csv(\"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/sample_submission.csv\")\nsubmission['path'] = submission['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\n\nema_model.eval()\nall_preds = []\n\nwith torch.no_grad():\n    for i in tqdm(range(0, len(submission), CFG[\"batch_size\"]), desc=\"Predicting\"):\n        batch_paths = submission['path'].iloc[i:i+CFG[\"batch_size\"]].tolist()\n\n        # preload images once\n        imgs_loaded = []\n        for pth in batch_paths:\n            with Image.open(pth) as im:\n                imgs_loaded.append(im.convert(\"RGB\"))\n\n        batch_sum = None\n        for tform in tta_transforms:\n            imgs = torch.stack([tform(img) for img in imgs_loaded]).to(device, non_blocking=True)\n            outputs = ema_model(imgs)\n            probs = torch.softmax(outputs, dim=1)\n            batch_sum = probs if batch_sum is None else (batch_sum + probs)\n\n        avg_probs = batch_sum / len(tta_transforms)\n        max_probs, argmax = avg_probs.max(1)\n\n        # threshold â†’ UNK\n        final_idx = [\n            a.item() if mp.item() >= CFG[\"unk_threshold\"] else (num_classes - 1)\n            for a, mp in zip(argmax, max_probs)\n        ]\n        all_preds.extend([idx_to_label[j] for j in final_idx])\n\nsubmission['style'] = all_preds\nout_path = \"submission_TTA_EMA_UNK_final.csv\"\nsubmission.to_csv(out_path, index=False)\nprint(f\"ðŸŽ¯ Saved to {out_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"0.80964","metadata":{}},{"cell_type":"code","source":"import os, copy, random, warnings\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom torchvision.transforms import AutoAugment, AutoAugmentPolicy\nfrom PIL import Image, ImageFile\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\n\n# ============================\n# 1) CONFIG & SEED\n# ============================\nCFG = {\n    \"image_dir\": \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/image\",\n    \"batch_size\": 32,\n    \"epochs_stage1\": 5,\n    \"epochs_stage2\": 25,\n    \"patience\": 6,\n    \"lr\": 3e-4,\n    \"weight_decay\": 1e-4,\n    \"label_smoothing\": 0.1,\n    \"ema_decay\": 0.999,\n    \"seed\": 42,\n    \"unk_threshold\": 0.4,\n    \"unk_margin\": 0.1  # à¸ªà¹ˆà¸§à¸™à¸•à¹ˆà¸²à¸‡ top1-top2 à¸­à¸¢à¹ˆà¸²à¸‡à¸™à¹‰à¸­à¸¢\n}\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_amp = (device.type == \"cuda\")\n\ndef seed_everything(seed=42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed); \n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(CFG[\"seed\"])\nImageFile.LOAD_TRUNCATED_IMAGES = True\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ============================\n# 2) Dataset\n# ============================\nclass ArtDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_path = row['path']\n        label = row['label']\n        with Image.open(img_path) as im:\n            image = im.convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# ============================\n# 3) Prepare Data\n# ============================\ntrain_csv = \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/train.csv\"\ndf = pd.read_csv(train_csv)\ndf['path'] = df['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\n\nlabel_to_idx = {label: idx for idx, label in enumerate(sorted(df['style'].unique()))}\nidx_to_label = {v: k for k, v in label_to_idx.items()}\ndf['label'] = df['style'].map(label_to_idx).astype(int)\n\ntrain_df, val_df = train_test_split(\n    df, test_size=0.2, stratify=df['label'], random_state=CFG[\"seed\"]\n)\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),\n                         (0.229, 0.224, 0.225))\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),\n                         (0.229, 0.224, 0.225))\n])\n\nnum_workers = min(4, os.cpu_count() or 1)\nuse_persistent = (num_workers > 0) and (device.type == \"cuda\")\n\ntrain_loader = DataLoader(\n    ArtDataset(train_df, train_transform),\n    batch_size=CFG[\"batch_size\"], shuffle=True, num_workers=num_workers,\n    pin_memory=(device.type==\"cuda\"), persistent_workers=use_persistent\n)\nval_loader = DataLoader(\n    ArtDataset(val_df, val_transform),\n    batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=num_workers,\n    pin_memory=(device.type==\"cuda\"), persistent_workers=use_persistent\n)\n\n# ============================\n# 4) Model\n# ============================\nnum_classes_orig = len(label_to_idx)\nnum_classes = num_classes_orig + 1  # à¹€à¸žà¸´à¹ˆà¸¡ UNK\nmodel = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\nin_features = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(in_features, num_classes)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=CFG[\"label_smoothing\"])\nscaler = torch.amp.GradScaler(\"cuda\", enabled=use_amp)\n\noptimizer = optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n    optimizer, T_max=CFG[\"epochs_stage1\"]+CFG[\"epochs_stage2\"]\n)\n\n# EMA model\nema_model = copy.deepcopy(model)\nfor p in ema_model.parameters():\n    p.requires_grad = False\n\n@torch.no_grad()\ndef update_ema(model, ema_model, decay):\n    msd = model.state_dict()\n    emsd = ema_model.state_dict()\n    for k, v in msd.items():\n        if v.dtype.is_floating_point:\n            emsd[k].mul_(decay).add_(v, alpha=1 - decay)\n        else:\n            emsd[k].copy_(v)\n\n# ============================\n# 5) Training Functions\n# ============================\ndef freeze_backbone(model, freeze=True):\n    for name, param in model.named_parameters():\n        if \"classifier\" not in name:\n            param.requires_grad = not freeze\n        else:\n            param.requires_grad = True\n\ndef train_one_epoch(loader):\n    model.train()\n    running_loss, correct, total = 0.0, 0, 0\n    for images, labels in tqdm(loader, leave=False, desc=\"Train\"):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        optimizer.zero_grad(set_to_none=True)\n        with torch.amp.autocast(\"cuda\", enabled=use_amp):\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        update_ema(model, ema_model, CFG[\"ema_decay\"])\n        running_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    return running_loss / max(1, len(loader)), 100.0 * correct / max(1, total)\n\n@torch.no_grad()\ndef evaluate(loader, eval_model):\n    eval_model.eval()\n    running_loss, correct, total = 0.0, 0, 0\n    for images, labels in tqdm(loader, leave=False, desc=\"Val\"):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        outputs = eval_model(images)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    return running_loss / max(1, len(loader)), 100.0 * correct / max(1, total)\n\ndef train_model(stage_epochs, freeze_back=True):\n    global best_acc, patience_counter, best_model_wts\n    freeze_backbone(model, freeze_back)\n    for epoch in range(stage_epochs):\n        print(f\"\\nEpoch {epoch+1}/{stage_epochs} | {'Freeze' if freeze_back else 'Unfreeze'} Backbone\")\n        train_loss, train_acc = train_one_epoch(train_loader)\n        val_loss, val_acc = evaluate(val_loader, model)\n        scheduler.step()\n        print(f\"Train Loss {train_loss:.4f} | Acc {train_acc:.2f}% || Val Loss {val_loss:.4f} | Acc {val_acc:.2f}%\")\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n            torch.save(best_model_wts, \"best_model.pth\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG[\"patience\"]:\n                print(\"Early stopping.\")\n                return\n\n# à¹€à¸›à¸´à¸” cuDNN benchmark à¹€à¸žà¸·à¹ˆà¸­à¹€à¸£à¹ˆà¸‡à¸„à¸§à¸²à¸¡à¹€à¸£à¹‡à¸§à¸–à¹‰à¸² input size à¸„à¸‡à¸—à¸µà¹ˆ\nif device.type == \"cuda\":\n    torch.backends.cudnn.benchmark = True\n\n# ============================\n# 6) Training\n# ============================\nbest_acc, patience_counter = 0.0, 0\nbest_model_wts = copy.deepcopy(model.state_dict())\n\ntrain_model(CFG[\"epochs_stage1\"], freeze_back=True)\ntrain_model(CFG[\"epochs_stage2\"], freeze_back=False)\n\nmodel.load_state_dict(best_model_wts)\nema_model.load_state_dict(best_model_wts)\ntorch.save(model.state_dict(), \"last_model.pth\")\nprint(f\"âœ… Best Val Acc: {best_acc:.2f}% | saved best_model.pth & last_model.pth\")\n\n# ============================\n# 7) Inference + TTA + UNK\n# ============================\ntta_transforms = [\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ]),\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomRotation(15),\n        transforms.RandomHorizontalFlip(p=1.0),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ]),\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ColorJitter(0.05, 0.05, 0.05, 0.02),\n        transforms.RandomPerspective(distortion_scale=0.2, p=0.3),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ]),\n    transforms.Compose([\n        transforms.Resize(256),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ]),\n]\n\nidx_to_label = {v: k for k, v in label_to_idx.items()}\nidx_to_label[num_classes-1] = \"UNK\"\n\nsubmission = pd.read_csv(\"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/sample_submission.csv\")\nsubmission['path'] = submission['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\n\nema_model.eval()\nall_preds = []\n\nwith torch.no_grad():\n    for i in tqdm(range(0, len(submission), CFG[\"batch_size\"]), desc=\"Predicting\"):\n        batch_paths = submission['path'].iloc[i:i+CFG[\"batch_size\"]].tolist()\n        imgs_loaded = []\n        for pth in batch_paths:\n            with Image.open(pth) as im:\n                imgs_loaded.append(im.convert(\"RGB\"))\n        batch_sum = None\n        for tform in tta_transforms:\n            imgs = torch.stack([tform(img) for img in imgs_loaded]).to(device, non_blocking=True)\n            outputs = ema_model(imgs)\n            probs = torch.softmax(outputs, dim=1)\n            batch_sum = probs if batch_sum is None else (batch_sum + probs)\n        avg_probs = batch_sum / len(tta_transforms)\n        top2_probs, top2_idxs = avg_probs.topk(2, dim=1)\n        final_idx = [\n            t1.item() if (t1_prob.item() >= CFG[\"unk_threshold\"] \n                          and (t1_prob - t2_prob).item() >= CFG[\"unk_margin\"]) \n            else num_classes - 1\n            for t1_prob, t2_prob, t1 in zip(top2_probs[:,0], top2_probs[:,1], top2_idxs[:,0])\n        ]\n        all_preds.extend([idx_to_label[j] for j in final_idx])\n\nsubmission['style'] = all_preds\nout_path = \"submission_TTA_EMA_UNK_final.csv\"\nsubmission.to_csv(out_path, index=False)\nprint(f\"ðŸŽ¯ Saved to {out_path}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":".2","metadata":{}},{"cell_type":"markdown","source":"0.85329","metadata":{}},{"cell_type":"code","source":"import os, copy, random, warnings\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom torchvision.transforms import AutoAugment, AutoAugmentPolicy\nfrom PIL import Image, ImageFile\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim.swa_utils import AveragedModel, SWALR\n\n# ============================\n# 1) CONFIG & SEED\n# ============================\nCFG = {\n    \"image_dir\": \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/image\",\n    \"batch_size\": 32,\n    \"epochs_stage1\": 5,\n    \"epochs_stage2\": 25,\n    \"patience\": 6,\n    \"lr\": 3e-4,\n    \"weight_decay\": 1e-4,\n    \"label_smoothing\": 0.1,\n    \"ema_decay\": 0.999,\n    \"seed\": 42,\n    \"unk_threshold\": 0.4,\n    \"unk_margin\": 0.1,\n    \"temperature\": 1.5,\n    \"mixup_alpha\": 0.4\n}\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_amp = (device.type == \"cuda\")\n\ndef seed_everything(seed=42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(CFG[\"seed\"])\nImageFile.LOAD_TRUNCATED_IMAGES = True\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ============================\n# 2) Dataset\n# ============================\nclass ArtDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_path = row['path']\n        label = row['label']\n        with Image.open(img_path) as im:\n            image = im.convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# ============================\n# 3) Prepare Data\n# ============================\ntrain_csv = \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/train.csv\"\ndf = pd.read_csv(train_csv)\ndf['path'] = df['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\n\nlabel_to_idx = {label: idx for idx, label in enumerate(sorted(df['style'].unique()))}\nidx_to_label = {v: k for k, v in label_to_idx.items()}\ndf['label'] = df['style'].map(label_to_idx).astype(int)\n\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=CFG[\"seed\"])\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),\n                         (0.229, 0.224, 0.225))\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),\n                         (0.229, 0.224, 0.225))\n])\n\nnum_workers = min(4, os.cpu_count() or 1)\nuse_persistent = (num_workers > 0) and (device.type == \"cuda\")\n\ntrain_loader = DataLoader(\n    ArtDataset(train_df, train_transform),\n    batch_size=CFG[\"batch_size\"], shuffle=True, num_workers=num_workers,\n    pin_memory=(device.type==\"cuda\"), persistent_workers=use_persistent\n)\nval_loader = DataLoader(\n    ArtDataset(val_df, val_transform),\n    batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=num_workers,\n    pin_memory=(device.type==\"cuda\"), persistent_workers=use_persistent\n)\n\n# ============================\n# 4) Model\n# ============================\nnum_classes_orig = len(label_to_idx)\nnum_classes = num_classes_orig + 1  # à¹€à¸žà¸´à¹ˆà¸¡ UNK\nmodel = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\nin_features = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(in_features, num_classes)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=CFG[\"label_smoothing\"])\nscaler = torch.cuda.amp.GradScaler(enabled=use_amp)\noptimizer = optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG[\"epochs_stage1\"]+CFG[\"epochs_stage2\"])\n\nema_model = copy.deepcopy(model)\nfor p in ema_model.parameters():\n    p.requires_grad = False\n\n@torch.no_grad()\ndef update_ema(model, ema_model, decay):\n    msd = model.state_dict()\n    emsd = ema_model.state_dict()\n    for k, v in msd.items():\n        if v.dtype.is_floating_point:\n            emsd[k].mul_(decay).add_(v, alpha=1 - decay)\n        else:\n            emsd[k].copy_(v)\n\n# ============================\n# 5) Mixup + CutMix\n# ============================\ndef mixup_data(x, y, alpha=1.0):\n    if alpha <= 0: return x, y, y, 1.0\n    lam = np.random.beta(alpha, alpha)\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(x.device)\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\ndef rand_bbox(size, lam):\n    W, H = size[2], size[3]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w, cut_h = int(W*cut_rat), int(H*cut_rat)\n    cx, cy = np.random.randint(W), np.random.randint(H)\n    bbx1, bby1 = np.clip(cx-cut_w//2, 0, W), np.clip(cy-cut_h//2, 0, H)\n    bbx2, bby2 = np.clip(cx+cut_w//2, 0, W), np.clip(cy+cut_h//2, 0, H)\n    return bbx1, bby1, bbx2, bby2\n\ndef cutmix_data(x, y, alpha=1.0):\n    if alpha <= 0: return x, y, y, 1.0\n    lam = np.random.beta(alpha, alpha)\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(x.device)\n    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n    x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n    y_a, y_b = y, y[index]\n    lam = 1 - ((bbx2-bbx1)*(bby2-bby1)/(x.size(-1)*x.size(-2)))\n    return x, y_a, y_b, lam\n\ndef cutmix_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\n# ============================\n# 6) Training Functions\n# ============================\ndef freeze_backbone(model, freeze=True):\n    for name, param in model.named_parameters():\n        if \"classifier\" not in name:\n            param.requires_grad = not freeze\n        else:\n            param.requires_grad = True\n\ndef train_one_epoch(loader, use_cutmix=False):\n    model.train()\n    running_loss, correct, total = 0.0, 0, 0\n    for images, labels in tqdm(loader, leave=False, desc=\"Train\"):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        if use_cutmix:\n            images, y_a, y_b, lam = cutmix_data(images, labels, CFG[\"mixup_alpha\"])\n            criterion_fn = cutmix_criterion\n        else:\n            images, y_a, y_b, lam = mixup_data(images, labels, CFG[\"mixup_alpha\"])\n            criterion_fn = mixup_criterion\n        optimizer.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast(enabled=use_amp):\n            outputs = model(images)\n            loss = criterion_fn(criterion, outputs, y_a, y_b, lam)\n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n        scaler.step(optimizer)\n        scaler.update()\n        update_ema(model, ema_model, CFG[\"ema_decay\"])\n        running_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    return running_loss / max(1, len(loader)), 100.0 * correct / max(1, total)\n\n@torch.no_grad()\ndef evaluate(loader, eval_model):\n    eval_model.eval()\n    running_loss, correct, total = 0.0, 0, 0\n    for images, labels in tqdm(loader, leave=False, desc=\"Val\"):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        outputs = eval_model(images)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    return running_loss / max(1, len(loader)), 100.0 * correct / max(1, total)\n\n# ============================\n# 7) Training Loop + SWA\n# ============================\nbest_acc, patience_counter = 0.0, 0\nbest_model_wts = copy.deepcopy(model.state_dict())\nswa_model = AveragedModel(model)\nswa_start = CFG[\"epochs_stage1\"]\nswa_scheduler = SWALR(optimizer, swa_lr=1e-5)\n\ndef train_model(stage_epochs, freeze_back=True, use_cutmix=False):\n    global best_acc, patience_counter, best_model_wts\n    freeze_backbone(model, freeze_back)\n    for epoch in range(stage_epochs):\n        print(f\"\\nEpoch {epoch+1}/{stage_epochs} | {'Freeze' if freeze_back else 'Unfreeze'} Backbone\")\n        train_loss, train_acc = train_one_epoch(train_loader, use_cutmix=use_cutmix)\n        val_loss, val_acc = evaluate(val_loader, model)\n\n        if not freeze_back and epoch >= swa_start:\n            swa_model.update_parameters(model)\n            swa_scheduler.step()\n        else:\n            scheduler.step()\n\n        print(f\"Train Loss {train_loss:.4f} | Acc {train_acc:.2f}% || Val Loss {val_loss:.4f} | Acc {val_acc:.2f}%\")\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n            torch.save(best_model_wts, \"best_model.pth\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG[\"patience\"]:\n                print(\"Early stopping.\")\n                return\n            elif patience_counter == 3:\n                for g in optimizer.param_groups:\n                    g['lr'] *= 0.2\n                print(f\"ðŸ”» Reduce LR to {optimizer.param_groups[0]['lr']}\")\n\nif device.type == \"cuda\":\n    torch.backends.cudnn.benchmark = True\n\n# ============================\n# 8) Run Training\n# ============================\ntrain_model(CFG[\"epochs_stage1\"], freeze_back=True, use_cutmix=False)\ntrain_model(CFG[\"epochs_stage2\"], freeze_back=False, use_cutmix=True)\n\ntorch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\ntorch.save(swa_model.module.state_dict(), \"swa_model.pth\")\nmodel.load_state_dict(best_model_wts)\nema_model.load_state_dict(best_model_wts)\ntorch.save(model.state_dict(), \"last_model.pth\")\nprint(f\"âœ… Best Val Acc: {best_acc:.2f}% | saved best_model.pth, last_model.pth & swa_model.pth\")\n\n# ============================\n# 9) Optimized Inference + TTA + UNK\n# ============================\ntta_transforms = [\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n    ]),\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomRotation(15),\n        transforms.RandomHorizontalFlip(p=1.0),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n    ]),\n]\n\nidx_to_label[num_classes-1] = \"UNK\"\nsubmission = pd.read_csv(\"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/sample_submission.csv\")\nsubmission['path'] = submission['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\n\nema_model.eval()\nall_preds = []\n\nwith torch.no_grad():\n    for i in tqdm(range(0, len(submission), CFG[\"batch_size\"]), desc=\"Predicting\"):\n        batch_paths = submission['path'].iloc[i:i+CFG[\"batch_size\"]].tolist()\n        imgs_loaded = [Image.open(p).convert(\"RGB\") for p in batch_paths]\n        batch_sum = None\n        for tform in tta_transforms:\n            imgs = torch.stack([tform(img) for img in imgs_loaded]).to(device)\n            outputs = ema_model(imgs)\n            probs = torch.softmax(outputs / CFG[\"temperature\"], dim=1)\n            batch_sum = probs if batch_sum is None else batch_sum + probs\n        avg_probs = batch_sum / len(tta_transforms)\n        top2_probs, top2_idxs = avg_probs.topk(2, dim=1)\n        final_idx = [\n            t1.item() if (t1_prob.item() >= CFG[\"unk_threshold\"] \n                          and (t1_prob - t2_prob).item() >= CFG[\"unk_margin\"]) \n            else num_classes-1\n            for t1_prob, t2_prob, t1 in zip(top2_probs[:,0], top2_probs[:,1], top2_idxs[:,0])\n        ]\n        all_preds.extend([idx_to_label[j] for j in final_idx])\n\nsubmission['style'] = all_preds\nout_path = \"submission_TTA_EMA_UNK_optimized.csv\"\nsubmission.to_csv(out_path, index=False)\nprint(f\"ðŸŽ¯ Saved to {out_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================\n# 1) IMPORTS\n# ============================\nimport os, copy, random, warnings\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom torchvision.transforms import AutoAugment, AutoAugmentPolicy\nfrom PIL import Image, ImageFile\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim.swa_utils import AveragedModel, SWALR\n\n# ============================\n# 2) CONFIG & SEED\n# ============================\nCFG = {\n    \"image_dir\": \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/image\",\n    \"batch_size\": 32,\n    \"epochs_stage1\": 5,\n    \"epochs_stage2\": 25,\n    \"patience\": 6,\n    \"lr\": 3e-4,\n    \"weight_decay\": 1e-4,\n    \"label_smoothing\": 0.1,\n    \"ema_decay\": 0.999,\n    \"seed\": 42,\n    \"unk_threshold\": 0.4,\n    \"unk_margin\": 0.1,\n    \"temperature\": 1.5,\n    \"mixup_alpha\": 0.4\n}\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_amp = (device.type == \"cuda\")\n\ndef seed_everything(seed=42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(CFG[\"seed\"])\nImageFile.LOAD_TRUNCATED_IMAGES = True\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\n\n# ============================\n# 3) DATASET\n# ============================\nclass ArtDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_path = row['path']\n        label = row['label']\n        with Image.open(img_path) as im:\n            image = im.convert(\"RGB\")\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n# ============================\n# 4) PREPARE DATA\n# ============================\ntrain_csv = \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/train.csv\"\ndf = pd.read_csv(train_csv)\ndf['path'] = df['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\n\nlabel_to_idx = {label: idx for idx, label in enumerate(sorted(df['style'].unique()))}\nidx_to_label = {v: k for k, v in label_to_idx.items()}\ndf['label'] = df['style'].map(label_to_idx).astype(int)\n\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=CFG[\"seed\"])\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),\n                         (0.229, 0.224, 0.225))\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406),\n                         (0.229, 0.224, 0.225))\n])\n\nnum_workers = os.cpu_count()  # à¹ƒà¸Šà¹‰à¹€à¸•à¹‡à¸¡à¸—à¸µà¹ˆ\nuse_persistent = (num_workers > 0) and (device.type == \"cuda\")\n\ntrain_loader = DataLoader(\n    ArtDataset(train_df, train_transform),\n    batch_size=CFG[\"batch_size\"], shuffle=True, num_workers=num_workers,\n    pin_memory=(device.type==\"cuda\"), persistent_workers=use_persistent\n)\nval_loader = DataLoader(\n    ArtDataset(val_df, val_transform),\n    batch_size=CFG[\"batch_size\"], shuffle=False, num_workers=num_workers,\n    pin_memory=(device.type==\"cuda\"), persistent_workers=use_persistent\n)\n\n# ============================\n# 5) MODEL\n# ============================\nnum_classes_orig = len(label_to_idx)\nnum_classes = num_classes_orig + 1  # à¹€à¸žà¸´à¹ˆà¸¡ UNK\nmodel = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\nin_features = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(in_features, num_classes)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=CFG[\"label_smoothing\"])\nscaler = torch.cuda.amp.GradScaler(enabled=use_amp)\noptimizer = optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG[\"epochs_stage1\"]+CFG[\"epochs_stage2\"])\n\nema_model = copy.deepcopy(model)\nfor p in ema_model.parameters():\n    p.requires_grad = False\n\n@torch.no_grad()\ndef update_ema(model, ema_model, decay):\n    msd = model.state_dict()\n    emsd = ema_model.state_dict()\n    for k, v in msd.items():\n        if v.dtype.is_floating_point:\n            emsd[k].mul_(decay).add_(v.detach(), alpha=1 - decay)\n        else:\n            emsd[k].copy_(v)\n\n# ============================\n# 6) MIXUP + CUTMIX\n# ============================\ndef mixup_data(x, y, alpha=1.0):\n    if alpha <= 0: return x, y, y, 1.0\n    lam = np.random.beta(alpha, alpha)\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(x.device)\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\ndef rand_bbox(size, lam):\n    W, H = size[3], size[2]\n    cut_rat = np.sqrt(1. - lam)\n    cut_w, cut_h = int(W*cut_rat), int(H*cut_rat)\n    cx, cy = np.random.randint(W), np.random.randint(H)\n    bbx1, bby1 = np.clip(cx-cut_w//2, 0, W), np.clip(cy-cut_h//2, 0, H)\n    bbx2, bby2 = np.clip(cx+cut_w//2, 0, W), np.clip(cy+cut_h//2, 0, H)\n    return bbx1, bby1, bbx2, bby2\n\ndef cutmix_data(x, y, alpha=1.0):\n    if alpha <= 0: return x, y, y, 1.0\n    lam = np.random.beta(alpha, alpha)\n    batch_size = x.size()[0]\n    index = torch.randperm(batch_size).to(x.device)\n    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n    x[:, :, bby1:bby2, bbx1:bbx2] = x[index, :, bby1:bby2, bbx1:bbx2]\n    y_a, y_b = y, y[index]\n    lam = 1 - ((bbx2-bbx1)*(bby2-bby1)/(x.size(-1)*x.size(-2)))\n    return x, y_a, y_b, lam\n\ndef cutmix_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n\n# ============================\n# 7) TRAINING\n# ============================\ndef freeze_backbone(model, freeze=True):\n    for name, param in model.named_parameters():\n        if \"classifier\" not in name:\n            param.requires_grad = not freeze\n        else:\n            param.requires_grad = True\n\ndef train_one_epoch(loader, use_cutmix=False):\n    model.train()\n    running_loss, correct, total = 0.0, 0, 0\n    for images, labels in tqdm(loader, leave=False, desc=\"Train\"):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        if use_cutmix:\n            images, y_a, y_b, lam = cutmix_data(images, labels, CFG[\"mixup_alpha\"])\n            criterion_fn = cutmix_criterion\n        else:\n            images, y_a, y_b, lam = mixup_data(images, labels, CFG[\"mixup_alpha\"])\n            criterion_fn = mixup_criterion\n\n        optimizer.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast(enabled=use_amp):\n            outputs = model(images)\n            loss = criterion_fn(criterion, outputs, y_a, y_b, lam)\n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n        scaler.step(optimizer)\n        scaler.update()\n        update_ema(model, ema_model, CFG[\"ema_decay\"])\n        running_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    return running_loss / max(1, len(loader)), 100.0 * correct / max(1, total)\n\n@torch.no_grad()\ndef evaluate(loader, eval_model):\n    eval_model.eval()\n    running_loss, correct, total = 0.0, 0, 0\n    for images, labels in tqdm(loader, leave=False, desc=\"Val\"):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        outputs = eval_model(images)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    return running_loss / max(1, len(loader)), 100.0 * correct / max(1, total)\n\nbest_acc, patience_counter = 0.0, 0\nbest_model_wts = copy.deepcopy(model.state_dict())\nswa_model = AveragedModel(model)\nswa_start = CFG[\"epochs_stage1\"]\nswa_scheduler = SWALR(optimizer, swa_lr=1e-5)\n\ndef train_model(stage_epochs, freeze_back=True, use_cutmix=False):\n    global best_acc, patience_counter, best_model_wts\n    freeze_backbone(model, freeze_back)\n    for epoch in range(stage_epochs):\n        print(f\"\\nEpoch {epoch+1}/{stage_epochs} | {'Freeze' if freeze_back else 'Unfreeze'} Backbone\")\n        train_loss, train_acc = train_one_epoch(train_loader, use_cutmix=use_cutmix)\n        val_loss, val_acc = evaluate(val_loader, model)\n\n        if not freeze_back and (epoch >= swa_start):\n            swa_model.update_parameters(model)\n            swa_scheduler.step()\n        else:\n            scheduler.step()\n\n        print(f\"Train Loss {train_loss:.4f} | Acc {train_acc:.2f}% || Val Loss {val_loss:.4f} | Acc {val_acc:.2f}%\")\n        if val_acc > best_acc:\n            best_acc = val_acc\n            best_model_wts = copy.deepcopy(model.state_dict())\n            torch.save(best_model_wts, \"best_model.pth\")\n            patience_counter = 0\n        else:\n            patience_counter += 1\n            if patience_counter >= CFG[\"patience\"]:\n                print(\"Early stopping.\")\n                return\n            elif patience_counter == 3:\n                for g in optimizer.param_groups:\n                    g['lr'] *= 0.2\n                print(f\"ðŸ”» Reduce LR to {optimizer.param_groups[0]['lr']}\")\n\n# ============================\n# 8) RUN TRAINING\n# ============================\nif device.type == \"cuda\":\n    torch.backends.cudnn.benchmark = True\n\ntrain_model(CFG[\"epochs_stage1\"], freeze_back=True, use_cutmix=False)\ntrain_model(CFG[\"epochs_stage2\"], freeze_back=False, use_cutmix=True)\n\ntorch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\ntorch.save(swa_model.module.state_dict(), \"swa_model.pth\")\nmodel.load_state_dict(best_model_wts)\nema_model.load_state_dict(best_model_wts)\ntorch.save(model.state_dict(), \"last_model.pth\")\nprint(f\"âœ… Best Val Acc: {best_acc:.2f}% | saved best_model.pth, last_model.pth & swa_model.pth\")\n\n# ============================\n# 9) INFERENCE + TTA + UNK\n# ============================\nidx_to_label[num_classes-1] = \"UNK\"\n\ndef predict_with_tta_paths(paths, eval_model, tta_transforms, batch_size=CFG[\"batch_size\"], \n                           temperature=CFG[\"temperature\"], dynamic_unk=True):\n    eval_model.eval()\n    preds_out = []\n    unk_count, seen = 0, 0\n    unk_threshold = CFG[\"unk_threshold\"]\n    unk_margin = CFG[\"unk_margin\"]\n\n    with torch.no_grad():\n        for i in tqdm(range(0, len(paths), batch_size), desc=\"Predicting\"):\n            batch_paths = paths[i:i+batch_size]\n            imgs_loaded = [Image.open(p).convert(\"RGB\") for p in batch_paths]\n            batch_sum = None\n            for tform in tta_transforms:\n                imgs = torch.stack([tform(img) for img in imgs_loaded]).to(device, non_blocking=True)\n                with torch.cuda.amp.autocast(enabled=use_amp):\n                    outputs = eval_model(imgs)\n                    probs = torch.softmax(outputs / temperature, dim=1)\n                batch_sum = probs if batch_sum is None else (batch_sum + probs)\n            avg_probs = batch_sum / len(tta_transforms)\n            top2_probs, top2_idxs = avg_probs.topk(2, dim=1)\n            final_idx = []\n            for t1_prob, t2_prob, t1 in zip(top2_probs[:, 0], top2_probs[:, 1], top2_idxs[:, 0]):\n                t1p, t2p = t1_prob.item(), t2_prob.item()\n                if (t1p >= unk_threshold) and ((t1p - t2p) >= unk_margin):\n                    final_idx.append(t1.item())\n                else:\n                    final_idx.append(num_classes - 1)\n            if dynamic_unk:\n                seen += len(final_idx)\n                unk_count += sum(1 for j in final_idx if j == num_classes - 1)\n                curr_unk_rate = unk_count / max(1, seen)\n                if curr_unk_rate > 0.30:\n                    unk_threshold = max(0.20, unk_threshold - 0.05)\n                elif curr_unk_rate < 0.05:\n                    unk_threshold = min(0.80, unk_threshold + 0.02)\n            preds_out.extend([idx_to_label[j] for j in final_idx])\n\n    if dynamic_unk:\n        print(f\"â„¹ï¸ Final UNK rate: {unk_count/max(1,seen):.2%} | final unk_threshold used: {unk_threshold:.2f}\")\n    return preds_out\n\nsubmission = pd.read_csv(\"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/sample_submission.csv\")\nsubmission['path'] = submission['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\n\ntta_transforms = [\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n    ]),\n    transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomRotation(15),\n        transforms.RandomHorizontalFlip(p=1.0),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n    ]),\n]\n\npreds = predict_with_tta_paths(\n    submission['path'].tolist(),\n    eval_model=ema_model,\n    tta_transforms=tta_transforms,\n    batch_size=CFG[\"batch_size\"],\n    temperature=CFG[\"temperature\"],\n    dynamic_unk=True\n)\n\nsubmission['style'] = preds\nout_path = \"submission_TTA_EMA_UNK_optimized.csv\"\nsubmission.to_csv(out_path, index=False)\nprint(f\"ðŸŽ¯ Saved to {out_path}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"0.87108\n","metadata":{}},{"cell_type":"code","source":"# ============================\n# 1) IMPORTS\n# ============================\nimport os, copy, random, warnings\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom torchvision.transforms import AutoAugment, AutoAugmentPolicy\nfrom PIL import Image, ImageFile\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim.swa_utils import AveragedModel, SWALR\nfrom timm.models.layers import DropPath\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n# ============================\n# 2) CONFIG & SEED\n# ============================\nCFG = {\n    \"image_dir\": \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/image\",\n    \"train_csv\": \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/train.csv\",\n    \"submission_csv\": \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/sample_submission.csv\",\n    \"batch_size\": 32,\n    \"epochs_stage1\": 5,\n    \"epochs_stage2\": 25,\n    \"patience\": 6,\n    \"lr\": 3e-4,\n    \"weight_decay\": 1e-4,\n    \"label_smoothing\": 0.1,\n    \"ema_decay\": 0.999,\n    \"seed\": 42,\n    \"unk_threshold\": 0.4,\n    \"unk_margin\": 0.1,\n    \"temperature\": 1.5,\n    \"mixup_alpha\": 0.4\n}\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_amp = (device.type==\"cuda\")\n\ndef seed_everything(seed=42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(CFG[\"seed\"])\n\n# ============================\n# 3) DATASET\n# ============================\nclass ArtDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n    def __len__(self): return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_path = row['path']\n        label = row['label']\n        with Image.open(img_path) as im:\n            image = im.convert(\"RGB\")\n        if self.transform: image = self.transform(image)\n        return image, label\n\n# ============================\n# 4) DATA PREP\n# ============================\ndf = pd.read_csv(CFG[\"train_csv\"])\ndf['path'] = df['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\nlabel_to_idx = {label: idx for idx, label in enumerate(sorted(df['style'].unique()))}\nidx_to_label = {v:k for k,v in label_to_idx.items()}\ndf['label'] = df['style'].map(label_to_idx).astype(int)\n\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=CFG[\"seed\"])\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.7,1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n])\nval_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n])\n\nnum_workers = os.cpu_count()\nuse_persistent = (num_workers>0) and (device.type==\"cuda\")\n\ntrain_loader = DataLoader(ArtDataset(train_df, train_transform), batch_size=CFG[\"batch_size\"],\n                          shuffle=True, num_workers=num_workers, pin_memory=(device.type==\"cuda\"),\n                          persistent_workers=use_persistent)\nval_loader = DataLoader(ArtDataset(val_df, val_transform), batch_size=CFG[\"batch_size\"],\n                        shuffle=False, num_workers=num_workers, pin_memory=(device.type==\"cuda\"),\n                        persistent_workers=use_persistent)\n\n# ============================\n# 5) MODEL: EfficientNetB4 + Dropout + Stochastic Depth\n# ============================\nclass EfficientNetB4_Enhanced(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        base_model = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\n        # stochastic depth\n        for name,module in base_model.features.named_modules():\n            if hasattr(module,'drop_path'): module.drop_path = DropPath(0.2)\n        in_features = base_model.classifier[1].in_features\n        self.model = base_model\n        self.model.classifier[1] = nn.Sequential(nn.Dropout(0.5), nn.Linear(in_features,num_classes))\n    def forward(self,x): return self.model(x)\n\nnum_classes_orig = len(label_to_idx)\nnum_classes = num_classes_orig + 1  # à¹€à¸žà¸´à¹ˆà¸¡ UNK\nmodel = EfficientNetB4_Enhanced(num_classes).to(device)\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=CFG[\"label_smoothing\"])\nscaler = torch.cuda.amp.GradScaler(enabled=use_amp)\noptimizer = optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG[\"epochs_stage1\"]+CFG[\"epochs_stage2\"])\n\nema_model = copy.deepcopy(model)\nfor p in ema_model.parameters(): p.requires_grad=False\nswa_model = AveragedModel(model)\nswa_start = CFG[\"epochs_stage1\"]\nswa_scheduler = SWALR(optimizer, swa_lr=1e-5)\n\n@torch.no_grad()\ndef update_ema(model, ema_model, decay):\n    msd = model.state_dict()\n    emsd = ema_model.state_dict()\n    for k,v in msd.items():\n        if v.dtype.is_floating_point: emsd[k].mul_(decay).add_(v.detach(), alpha=1-decay)\n        else: emsd[k].copy_(v)\n\n# ============================\n# 6) MIXUP + CUTMIX ADVANCED\n# ============================\ndef mixup_data(x, y, alpha=0.4):\n    lam = np.random.beta(alpha, alpha) if alpha>0 else 1.0\n    index = torch.randperm(x.size(0)).to(x.device)\n    return lam*x + (1-lam)*x[index,:], y, y[index], lam\n\ndef cutmix_data(x, y, alpha=0.4):\n    lam = np.random.beta(alpha, alpha) if alpha>0 else 1.0\n    index = torch.randperm(x.size(0)).to(x.device)\n    W,H = x.size(3), x.size(2)\n    cut_rat = np.sqrt(1-lam)\n    cut_w, cut_h = int(W*cut_rat), int(H*cut_rat)\n    cx,cy = np.random.randint(W), np.random.randint(H)\n    bbx1, bby1 = np.clip(cx-cut_w//2,0,W), np.clip(cy-cut_h//2,0,H)\n    bbx2, bby2 = np.clip(cx+cut_w//2,0,W), np.clip(cy+cut_h//2,0,H)\n    x[:,:,bby1:bby2,bbx1:bbx2] = x[index,:,bby1:bby2,bbx1:bbx2]\n    lam = 1-((bbx2-bbx1)*(bby2-bby1)/(W*H))\n    return x, y, y[index], lam\n\ndef mixup_cutmix_prob(x,y,alpha=0.4,prob_cutmix=0.5):\n    return cutmix_data(x,y,alpha) if np.random.rand()<prob_cutmix else mixup_data(x,y,alpha)\n\ndef mixup_cutmix_criterion(pred,y_a,y_b,lam):\n    return lam*criterion(pred,y_a)+(1-lam)*criterion(pred,y_b)\n\n# ============================\n# 7) TRAINING FUNCTIONS\n# ============================\ndef freeze_backbone(model, freeze=True):\n    for name,param in model.named_parameters():\n        param.requires_grad = not freeze if \"classifier\" not in name else True\n\ndef train_one_epoch_adv(loader):\n    model.train(); running_loss, correct, total=0.,0,0\n    for images, labels in tqdm(loader, leave=False, desc=\"Train\"):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        images, y_a, y_b, lam = mixup_cutmix_prob(images, labels, CFG[\"mixup_alpha\"], 0.5)\n        optimizer.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast(enabled=use_amp):\n            outputs = model(images)\n            loss = mixup_cutmix_criterion(outputs,y_a,y_b,lam)\n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(),10.0)\n        scaler.step(optimizer); scaler.update()\n        update_ema(model, ema_model, CFG[\"ema_decay\"])\n        running_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds==labels).sum().item()\n        total += labels.size(0)\n    return running_loss/max(1,len(loader)),100.*correct/max(1,total)\n\n@torch.no_grad()\ndef evaluate(loader, eval_model):\n    eval_model.eval(); running_loss, correct, total=0.,0,0\n    for images, labels in tqdm(loader, leave=False, desc=\"Val\"):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        outputs = eval_model(images)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds==labels).sum().item()\n        total += labels.size(0)\n    return running_loss/max(1,len(loader)),100.*correct/max(1,total)\n\nbest_acc, patience_counter = 0.,0\nbest_model_wts = copy.deepcopy(model.state_dict())\n\ndef train_model(stage_epochs, freeze_back=True):\n    global best_acc, patience_counter, best_model_wts\n    freeze_backbone(model, freeze_back)\n    for epoch in range(stage_epochs):\n        print(f\"\\nEpoch {epoch+1}/{stage_epochs} | {'Freeze' if freeze_back else 'Unfreeze'} Backbone\")\n        train_loss, train_acc = train_one_epoch_adv(train_loader)\n        val_loss, val_acc = evaluate(val_loader, model)\n        if not freeze_back and epoch>=swa_start: swa_model.update_parameters(model); swa_scheduler.step()\n        else: scheduler.step()\n        print(f\"Train Loss {train_loss:.4f} | Acc {train_acc:.2f}% || Val Loss {val_loss:.4f} | Acc {val_acc:.2f}%\")\n        if val_acc>best_acc:\n            best_acc=val_acc; best_model_wts=copy.deepcopy(model.state_dict())\n            torch.save(best_model_wts,\"best_model.pth\"); patience_counter=0\n        else:\n            patience_counter+=1\n            if patience_counter>=CFG[\"patience\"]: print(\"Early stopping.\"); return\n            elif patience_counter==3:\n                for g in optimizer.param_groups: g['lr']*=0.2\n                print(f\"ðŸ”» Reduce LR to {optimizer.param_groups[0]['lr']}\")\n\n# ============================\n# 8) RUN TRAINING\n# ============================\nif device.type==\"cuda\": torch.backends.cudnn.benchmark=True\ntrain_model(CFG[\"epochs_stage1\"], freeze_back=True)\ntrain_model(CFG[\"epochs_stage2\"], freeze_back=False)\ntorch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n\ntorch.save(swa_model.state_dict(), \"swa_model.pth\")\ntorch.save(model.state_dict(), \"last_model.pth\")\ntorch.save(best_model_wts, \"best_model.pth\")\nmodel.load_state_dict(best_model_wts)\nema_model.load_state_dict(best_model_wts)\nprint(f\"âœ… Best Val Acc: {best_acc:.2f}% | saved best_model.pth, last_model.pth & swa_model.pth\")\n\n# ============================\n# 9) INFERENCE + TTA + Dynamic UNK + Ensemble\n# ============================\nidx_to_label[num_classes-1] = \"UNK\"\ndef combine_ema_swa(ema_model, swa_model, base_model):\n    final_model = copy.deepcopy(base_model)\n    final_sd = final_model.state_dict()\n    ema_sd = ema_model.state_dict(); swa_sd = swa_model.state_dict()\n    for k in final_sd.keys():\n        if k in ema_sd and k in swa_sd: final_sd[k].copy_(0.5*ema_sd[k]+0.5*swa_sd[k])\n    final_model.load_state_dict(final_sd)\n    return final_model\n\nensemble_model = combine_ema_swa(ema_model, swa_model, model).to(device)\n\ntta_transforms = [\n    transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))]),\n    transforms.Compose([transforms.Resize((224,224)), transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor(), transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))]),\n    transforms.Compose([transforms.Resize((224,224)), transforms.RandomRotation(15), transforms.ToTensor(), transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))]),\n    transforms.Compose([transforms.Resize((224,224)), transforms.ColorJitter(0.2,0.2,0.2,0.1), transforms.ToTensor(), transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))])\n]\n\nsubmission = pd.read_csv(CFG[\"submission_csv\"])\nsubmission['path'] = submission['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\n\npreds = predict_with_tta_paths(submission['path'].tolist(), eval_model=ensemble_model,\n                               tta_transforms=tta_transforms, batch_size=CFG[\"batch_size\"],\n                               temperature=CFG[\"temperature\"], dynamic_unk=True)\n\nsubmission['style'] = preds\nsubmission.to_csv(\"submission_TTA_EMA_SWA_UNK_Enhanced.csv\", index=False)\nprint(f\"ðŸŽ¯ Saved to submission_TTA_EMA_SWA_UNK_Enhanced.csv\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"0.87277","metadata":{}},{"cell_type":"code","source":"# ============================\n# 1) IMPORTS\n# ============================\nimport os, copy, random, warnings\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom torchvision.transforms import AutoAugment, AutoAugmentPolicy\nfrom PIL import Image, ImageFile\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim.swa_utils import AveragedModel, SWALR\nfrom timm.models.layers import DropPath\n\nwarnings.filterwarnings(\"ignore\", category=UserWarning)\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n# ============================\n# 2) CONFIG & SEED\n# ============================\nCFG = {\n    \"image_dir\": \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/image\",\n    \"train_csv\": \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/train.csv\",\n    \"submission_csv\": \"/kaggle/input/saig-tech-mastery-2025-art-style-classification/competition/sample_submission.csv\",\n    \"batch_size\": 32,\n    \"epochs_stage1\": 5,\n    \"epochs_stage2\": 25,\n    \"patience\": 6,\n    \"lr\": 3e-4,\n    \"weight_decay\": 1e-4,\n    \"label_smoothing\": 0.1,\n    \"ema_decay\": 0.999,\n    \"seed\": 42,\n    \"unk_threshold\": 0.4,\n    \"unk_margin\": 0.1,\n    \"temperature\": 1.5,\n    \"mixup_alpha\": 0.4\n}\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_amp = (device.type==\"cuda\")\n\ndef seed_everything(seed=42):\n    random.seed(seed); np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\nseed_everything(CFG[\"seed\"])\n\n# ============================\n# 3) DATASET\n# ============================\nclass ArtDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.transform = transform\n    def __len__(self): return len(self.df)\n    def __getitem__(self, idx):\n        row = self.df.loc[idx]\n        img_path = row['path']\n        label = row['label']\n        with Image.open(img_path) as im:\n            image = im.convert(\"RGB\")\n        if self.transform: image = self.transform(image)\n        return image, label\n\n# ============================\n# 4) DATA PREP\n# ============================\ndf = pd.read_csv(CFG[\"train_csv\"])\ndf['path'] = df['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\nlabel_to_idx = {label: idx for idx, label in enumerate(sorted(df['style'].unique()))}\nidx_to_label = {v:k for k,v in label_to_idx.items()}\ndf['label'] = df['style'].map(label_to_idx).astype(int)\n\ntrain_df, val_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=CFG[\"seed\"])\n\ntrain_transform = transforms.Compose([\n    transforms.RandomResizedCrop(224, scale=(0.7,1.0)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    AutoAugment(policy=AutoAugmentPolicy.IMAGENET),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n])\nval_transform = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))\n])\n\nnum_workers = os.cpu_count()\nuse_persistent = (num_workers>0) and (device.type==\"cuda\")\n\ntrain_loader = DataLoader(ArtDataset(train_df, train_transform), batch_size=CFG[\"batch_size\"],\n                          shuffle=True, num_workers=num_workers, pin_memory=(device.type==\"cuda\"),\n                          persistent_workers=use_persistent)\nval_loader = DataLoader(ArtDataset(val_df, val_transform), batch_size=CFG[\"batch_size\"],\n                        shuffle=False, num_workers=num_workers, pin_memory=(device.type==\"cuda\"),\n                        persistent_workers=use_persistent)\n\n# ============================\n# 5) MODEL: EfficientNetB4 + Dropout + Stochastic Depth\n# ============================\nclass EfficientNetB4_Enhanced(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n        base_model = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\n        # stochastic depth\n        for name,module in base_model.features.named_modules():\n            if hasattr(module,'drop_path'): module.drop_path = DropPath(0.2)\n        in_features = base_model.classifier[1].in_features\n        self.model = base_model\n        self.model.classifier[1] = nn.Sequential(nn.Dropout(0.5), nn.Linear(in_features,num_classes))\n    def forward(self,x): return self.model(x)\n\nnum_classes_orig = len(label_to_idx)\nnum_classes = num_classes_orig + 1  # à¹€à¸žà¸´à¹ˆà¸¡ UNK\nmodel = EfficientNetB4_Enhanced(num_classes).to(device)\n\ncriterion = nn.CrossEntropyLoss(label_smoothing=CFG[\"label_smoothing\"])\nscaler = torch.cuda.amp.GradScaler(enabled=use_amp)\noptimizer = optim.AdamW(model.parameters(), lr=CFG[\"lr\"], weight_decay=CFG[\"weight_decay\"])\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=CFG[\"epochs_stage1\"]+CFG[\"epochs_stage2\"])\n\nema_model = copy.deepcopy(model)\nfor p in ema_model.parameters(): p.requires_grad=False\nswa_model = AveragedModel(model)\nswa_start = CFG[\"epochs_stage1\"]\nswa_scheduler = SWALR(optimizer, swa_lr=1e-5)\n\n@torch.no_grad()\ndef update_ema(model, ema_model, decay):\n    msd = model.state_dict()\n    emsd = ema_model.state_dict()\n    for k,v in msd.items():\n        if v.dtype.is_floating_point: emsd[k].mul_(decay).add_(v.detach(), alpha=1-decay)\n        else: emsd[k].copy_(v)\n\n# ============================\n# 6) MIXUP + CUTMIX ADVANCED\n# ============================\ndef mixup_data(x, y, alpha=0.4):\n    lam = np.random.beta(alpha, alpha) if alpha>0 else 1.0\n    index = torch.randperm(x.size(0)).to(x.device)\n    return lam*x + (1-lam)*x[index,:], y, y[index], lam\n\ndef cutmix_data(x, y, alpha=0.4):\n    lam = np.random.beta(alpha, alpha) if alpha>0 else 1.0\n    index = torch.randperm(x.size(0)).to(x.device)\n    W,H = x.size(3), x.size(2)\n    cut_rat = np.sqrt(1-lam)\n    cut_w, cut_h = int(W*cut_rat), int(H*cut_rat)\n    cx,cy = np.random.randint(W), np.random.randint(H)\n    bbx1, bby1 = np.clip(cx-cut_w//2,0,W), np.clip(cy-cut_h//2,0,H)\n    bbx2, bby2 = np.clip(cx+cut_w//2,0,W), np.clip(cy+cut_h//2,0,H)\n    x[:,:,bby1:bby2,bbx1:bbx2] = x[index,:,bby1:bby2,bbx1:bbx2]\n    lam = 1-((bbx2-bbx1)*(bby2-bby1)/(W*H))\n    return x, y, y[index], lam\n\ndef mixup_cutmix_prob(x,y,alpha=0.4,prob_cutmix=0.5):\n    return cutmix_data(x,y,alpha) if np.random.rand()<prob_cutmix else mixup_data(x,y,alpha)\n\ndef mixup_cutmix_criterion(pred,y_a,y_b,lam):\n    return lam*criterion(pred,y_a)+(1-lam)*criterion(pred,y_b)\n\n# ============================\n# 7) TRAINING FUNCTIONS\n# ============================\ndef freeze_backbone(model, freeze=True):\n    for name,param in model.named_parameters():\n        param.requires_grad = not freeze if \"classifier\" not in name else True\n\ndef train_one_epoch_adv(loader):\n    model.train(); running_loss, correct, total=0.,0,0\n    for images, labels in tqdm(loader, leave=False, desc=\"Train\"):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        images, y_a, y_b, lam = mixup_cutmix_prob(images, labels, CFG[\"mixup_alpha\"], 0.5)\n        optimizer.zero_grad(set_to_none=True)\n        with torch.cuda.amp.autocast(enabled=use_amp):\n            outputs = model(images)\n            loss = mixup_cutmix_criterion(outputs,y_a,y_b,lam)\n        scaler.scale(loss).backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(),10.0)\n        scaler.step(optimizer); scaler.update()\n        update_ema(model, ema_model, CFG[\"ema_decay\"])\n        running_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds==labels).sum().item()\n        total += labels.size(0)\n    return running_loss/max(1,len(loader)),100.*correct/max(1,total)\n\n@torch.no_grad()\ndef evaluate(loader, eval_model):\n    eval_model.eval(); running_loss, correct, total=0.,0,0\n    for images, labels in tqdm(loader, leave=False, desc=\"Val\"):\n        images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n        outputs = eval_model(images)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item()\n        preds = outputs.argmax(1)\n        correct += (preds==labels).sum().item()\n        total += labels.size(0)\n    return running_loss/max(1,len(loader)),100.*correct/max(1,total)\n\nbest_acc, patience_counter = 0.,0\nbest_model_wts = copy.deepcopy(model.state_dict())\n\ndef train_model(stage_epochs, freeze_back=True):\n    global best_acc, patience_counter, best_model_wts\n    freeze_backbone(model, freeze_back)\n    for epoch in range(stage_epochs):\n        print(f\"\\nEpoch {epoch+1}/{stage_epochs} | {'Freeze' if freeze_back else 'Unfreeze'} Backbone\")\n        train_loss, train_acc = train_one_epoch_adv(train_loader)\n        val_loss, val_acc = evaluate(val_loader, model)\n        if not freeze_back and epoch>=swa_start: swa_model.update_parameters(model); swa_scheduler.step()\n        else: scheduler.step()\n        print(f\"Train Loss {train_loss:.4f} | Acc {train_acc:.2f}% || Val Loss {val_loss:.4f} | Acc {val_acc:.2f}%\")\n        if val_acc>best_acc:\n            best_acc=val_acc; best_model_wts=copy.deepcopy(model.state_dict())\n            torch.save(best_model_wts,\"best_model.pth\"); patience_counter=0\n        else:\n            patience_counter+=1\n            if patience_counter>=CFG[\"patience\"]: print(\"Early stopping.\"); return\n            elif patience_counter==3:\n                for g in optimizer.param_groups: g['lr']*=0.2\n                print(f\"ðŸ”» Reduce LR to {optimizer.param_groups[0]['lr']}\")\n\n# ============================\n# 8) RUN TRAINING\n# ============================\nif device.type==\"cuda\": torch.backends.cudnn.benchmark=True\ntrain_model(CFG[\"epochs_stage1\"], freeze_back=True)\ntrain_model(CFG[\"epochs_stage2\"], freeze_back=False)\ntorch.optim.swa_utils.update_bn(train_loader, swa_model, device=device)\n\ntorch.save(swa_model.state_dict(), \"swa_model.pth\")\ntorch.save(model.state_dict(), \"last_model.pth\")\ntorch.save(best_model_wts, \"best_model.pth\")\nmodel.load_state_dict(best_model_wts)\nema_model.load_state_dict(best_model_wts)\nprint(f\"âœ… Best Val Acc: {best_acc:.2f}% | saved best_model.pth, last_model.pth & swa_model.pth\")\n\n# ============================\n# 9) INFERENCE + TTA + Dynamic UNK + Ensemble\n# ============================\nidx_to_label[num_classes-1] = \"UNK\"\ndef combine_ema_swa(ema_model, swa_model, base_model):\n    final_model = copy.deepcopy(base_model)\n    final_sd = final_model.state_dict()\n    ema_sd = ema_model.state_dict(); swa_sd = swa_model.state_dict()\n    for k in final_sd.keys():\n        if k in ema_sd and k in swa_sd: final_sd[k].copy_(0.5*ema_sd[k]+0.5*swa_sd[k])\n    final_model.load_state_dict(final_sd)\n    return final_model\n\nensemble_model = combine_ema_swa(ema_model, swa_model, model).to(device)\n\ntta_transforms = [\n    transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor(), transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))]),\n    transforms.Compose([transforms.Resize((224,224)), transforms.RandomHorizontalFlip(p=1.0), transforms.ToTensor(), transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))]),\n    transforms.Compose([transforms.Resize((224,224)), transforms.RandomRotation(15), transforms.ToTensor(), transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))]),\n    transforms.Compose([transforms.Resize((224,224)), transforms.ColorJitter(0.2,0.2,0.2,0.1), transforms.ToTensor(), transforms.Normalize((0.485,0.456,0.406),(0.229,0.224,0.225))])\n]\n\n# ============================\n# 10) PREDICT FUNCTION\n# ============================\n@torch.no_grad()\ndef predict_with_tta_paths(image_paths, eval_model, tta_transforms, batch_size, temperature=1.0, dynamic_unk=True):\n    eval_model.eval()\n    preds_all = []\n\n    for transform in tta_transforms:\n        dataset = ArtDataset(\n            pd.DataFrame({\"path\": image_paths, \"label\": [0]*len(image_paths)}),\n            transform=transform\n        )\n        loader = DataLoader(dataset, batch_size=batch_size, shuffle=False,\n                            num_workers=os.cpu_count(),\n                            pin_memory=(device.type==\"cuda\"))\n\n        probs_list = []\n        for images, _ in tqdm(loader, leave=False, desc=\"TTA\"):\n            images = images.to(device, non_blocking=True)\n            outputs = eval_model(images) / temperature\n            probs = torch.softmax(outputs, dim=1)\n            probs_list.append(probs.cpu().numpy())\n        \n        preds_all.append(np.concatenate(probs_list, axis=0))\n        torch.cuda.empty_cache()  # cleanup GPU memory\n\n    # average probs across TTA runs\n    probs_mean = np.mean(preds_all, axis=0)\n\n    if dynamic_unk:\n        max_probs = probs_mean.max(axis=1)\n        preds = probs_mean.argmax(axis=1)\n        unk_idx = num_classes - 1\n        preds[max_probs < CFG[\"unk_threshold\"]] = unk_idx\n    else:\n        preds = probs_mean.argmax(axis=1)\n\n    return [idx_to_label[p] for p in preds]\n\n# ============================\n# 11) RUN FINAL INFERENCE\n# ============================\nsubmission = pd.read_csv(CFG[\"submission_csv\"])\nsubmission['path'] = submission['uuid'].apply(lambda x: os.path.join(CFG[\"image_dir\"], f\"{x}.png\"))\n\npreds = predict_with_tta_paths(\n    submission['path'].tolist(),\n    eval_model=ensemble_model,\n    tta_transforms=tta_transforms,\n    batch_size=CFG[\"batch_size\"],\n    temperature=CFG[\"temperature\"],\n    dynamic_unk=True\n)\n\nsubmission['style'] = preds\nsubmission.to_csv(\"submission_TTA_EMA_SWA_UNK_Enhanced.csv\", index=False)\nprint(f\"ðŸŽ¯ Saved to submission_TTA_EMA_SWA_UNK_Enhanced.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-02T14:02:21.154525Z","iopub.execute_input":"2025-09-02T14:02:21.155214Z","iopub.status.idle":"2025-09-02T14:23:10.781515Z","shell.execute_reply.started":"2025-09-02T14:02:21.155188Z","shell.execute_reply":"2025-09-02T14:23:10.780501Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\nDownloading: \"https://download.pytorch.org/models/efficientnet_b4_rwightman-23ab8bcd.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_rwightman-23ab8bcd.pth\n100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 74.5M/74.5M [00:00<00:00, 216MB/s]\n/tmp/ipykernel_36/2354313897.py:128: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/5 | Freeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"Train:   0%|          | 0/162 [00:00<?, ?it/s]/tmp/ipykernel_36/2354313897.py:186: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n  with torch.cuda.amp.autocast(enabled=use_amp):\n                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 2.2070 | Acc 25.75% || Val Loss 2.0334 | Acc 60.46%\n\nEpoch 2/5 | Freeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 2.0083 | Acc 38.72% || Val Loss 1.8487 | Acc 68.49%\n\nEpoch 3/5 | Freeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.8745 | Acc 42.14% || Val Loss 1.6788 | Acc 72.05%\n\nEpoch 4/5 | Freeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.8059 | Acc 42.87% || Val Loss 1.5746 | Acc 73.59%\n\nEpoch 5/5 | Freeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.7329 | Acc 43.51% || Val Loss 1.4873 | Acc 75.14%\n\nEpoch 1/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.5407 | Acc 51.80% || Val Loss 1.0233 | Acc 83.47%\n\nEpoch 2/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.3964 | Acc 55.20% || Val Loss 0.9046 | Acc 87.18%\n\nEpoch 3/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.3311 | Acc 57.40% || Val Loss 0.8551 | Acc 89.50%\n\nEpoch 4/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.2975 | Acc 56.84% || Val Loss 0.8339 | Acc 89.65%\n\nEpoch 5/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.2014 | Acc 61.57% || Val Loss 0.7741 | Acc 90.35%\n\nEpoch 6/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.2089 | Acc 61.11% || Val Loss 0.7605 | Acc 91.20%\n\nEpoch 7/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.1509 | Acc 65.05% || Val Loss 0.7534 | Acc 91.58%\n\nEpoch 8/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.1490 | Acc 64.49% || Val Loss 0.7602 | Acc 91.97%\n\nEpoch 9/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.1690 | Acc 63.14% || Val Loss 0.7435 | Acc 92.74%\n\nEpoch 10/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.1496 | Acc 62.40% || Val Loss 0.7252 | Acc 92.36%\n\nEpoch 11/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.1070 | Acc 66.73% || Val Loss 0.7279 | Acc 92.43%\n\nEpoch 12/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.1020 | Acc 62.40% || Val Loss 0.7241 | Acc 93.20%\n\nEpoch 13/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.1075 | Acc 62.81% || Val Loss 0.7213 | Acc 92.90%\n\nEpoch 14/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.1518 | Acc 60.88% || Val Loss 0.7285 | Acc 93.05%\n\nEpoch 15/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.1506 | Acc 64.32% || Val Loss 0.7376 | Acc 92.90%\nðŸ”» Reduce LR to 2.0000000000000003e-06\n\nEpoch 16/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.0887 | Acc 64.28% || Val Loss 0.7174 | Acc 92.97%\n\nEpoch 17/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.1146 | Acc 63.37% || Val Loss 0.7111 | Acc 92.97%\n\nEpoch 18/25 | Unfreeze Backbone\n","output_type":"stream"},{"name":"stderr","text":"                                                        \r","output_type":"stream"},{"name":"stdout","text":"Train Loss 1.0874 | Acc 65.69% || Val Loss 0.7227 | Acc 93.20%\nEarly stopping.\nâœ… Best Val Acc: 93.20% | saved best_model.pth, last_model.pth & swa_model.pth\n","output_type":"stream"},{"name":"stderr","text":"                                                    ","output_type":"stream"},{"name":"stdout","text":"ðŸŽ¯ Saved to submission_TTA_EMA_SWA_UNK_Enhanced.csv\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":3}]}